{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab10_2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaver/NLP2019/blob/master/Lab10_2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTPzwv5jObxg",
        "colab_type": "text"
      },
      "source": [
        "In this lab, we will use Pytorch (and torchtext) to classify surnames to nationalities using a recurrent neural net.\n",
        "\n",
        "Use a Colab runtime with GPU so that training is faster.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxI9zaZCOz89",
        "colab_type": "code",
        "outputId": "a5faed03-4aec-4ebf-ae0c-2e97e708d0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch \n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuT0Z2p0O3_W",
        "colab_type": "text"
      },
      "source": [
        "First, we'll download the datafiles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rbddDkYOxl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -f names_train.csv names_test.csv\n",
        "!wget -q --no-check-certificate https://phon.ioc.ee/~tanela/tmp/names_train.csv\n",
        "!wget -q --no-check-certificate https://phon.ioc.ee/~tanela/tmp/names_test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s74JEjnO-WN",
        "colab_type": "text"
      },
      "source": [
        "The data files are CSV (actually, TSV -- tab-separated values) files, containing the name and the corresponding nationality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_K6WdYQO7lW",
        "colab_type": "code",
        "outputId": "416a498f-f1f4-4dad-dded-88510b6da628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head names_train.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tadhgan\tIrish\n",
            "Kingsley\tEnglish\n",
            "Fern√°ndez\tSpanish\n",
            "Paterson\tEnglish\n",
            "Friel\tEnglish\n",
            "Bahar\tArabic\n",
            "Mifsud\tArabic\n",
            "Vedischev\tRussian\n",
            "Suchanka\tCzech\n",
            "Jindra\tCzech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4tJUlOQPRLU",
        "colab_type": "text"
      },
      "source": [
        "Let's load the data into Torchtext dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsn1W_ZgPK2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data\n",
        "from torchtext import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohq88uh_PZCs",
        "colab_type": "text"
      },
      "source": [
        "First, we define the fields. We use a special tokenizer (`list`) for our NAME field which results in the characters of the name to be treated as individual tokens:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZiogZckPW24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME = data.Field(tokenize=list, init_token=\"<bos>\", eos_token=\"<eos>\", include_lengths=True, batch_first=True)\n",
        "LABEL = data.Field(sequential=False)\n",
        "\n",
        "train_dataset, test_dataset = data.TabularDataset.splits(path=\".\", train='names_train.csv', test='names_test.csv', format='tsv', skip_header=True, fields=[('name', NAME), ('label', LABEL)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x52dwbnAPmsL",
        "colab_type": "code",
        "outputId": "88df01a9-e76a-4538-a63b-b0e351409948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_dataset))\n",
        "print(train_dataset[0].name, train_dataset[0].label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8232\n",
            "['K', 'i', 'n', 'g', 's', 'l', 'e', 'y'] English\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagHMCKwRp4C",
        "colab_type": "text"
      },
      "source": [
        "Next, we can build the vocabularies for both our fields:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU92QDcDPr1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NAME.build_vocab(train_dataset)\n",
        "LABEL.build_vocab(train_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LIe0k8-RyQo",
        "colab_type": "text"
      },
      "source": [
        "Here is the mapping from nationalities to IDs. Again, the vocabulary uses a special ID for the unknown labels (`<unk>`) that we don't need. Therefore, we'll subtract 1 from the label ID later when we train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_DPpgFJRuLA",
        "colab_type": "code",
        "outputId": "84c7fffb-79e3-47bb-b8a7-ca1e7901deb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'<unk>': 0,\n",
              "             'Arabic': 3,\n",
              "             'Chinese': 11,\n",
              "             'Czech': 7,\n",
              "             'Dutch': 9,\n",
              "             'English': 1,\n",
              "             'French': 10,\n",
              "             'German': 5,\n",
              "             'Greek': 13,\n",
              "             'Irish': 12,\n",
              "             'Italian': 6,\n",
              "             'Japanese': 4,\n",
              "             'Korean': 15,\n",
              "             'Polish': 14,\n",
              "             'Portuguese': 18,\n",
              "             'Russian': 2,\n",
              "             'Scottish': 16,\n",
              "             'Spanish': 8,\n",
              "             'Vietnamese': 17})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhLma-g3SISn",
        "colab_type": "text"
      },
      "source": [
        "Next, we define the batch iterators for both or train and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1hNBKO8Rw3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter, test_iter = data.BucketIterator.splits((train_dataset, test_dataset), batch_size=32,  device=device, repeat=False)\n",
        "# The following two lines are needed to work around a bug in Torchtext. It will be fixed soon (I hope)\n",
        "test_iter.sort_within_batch = train_iter.sort_within_batch\n",
        "test_iter.sort = train_iter.sort\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFu-XXo-SbQ2",
        "colab_type": "text"
      },
      "source": [
        "The iterators return batches of data and corresponding labels, all turned into matrices.\n",
        "\n",
        "Note that we used `include_lengths=True` when constructing the NAME field. Because of that, the `name` field of each batch includes two tensors: a 32 x `max_length` tensor of character IDs in the batch, and a vector of 32 elements whose values correspond to actual name lengths in this batch. We will need the lengths later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PJnXdWVSYeg",
        "colab_type": "code",
        "outputId": "3a78c2b1-3237-4243-d2ba-4df659f011d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "batch = next(iter(test_iter))\n",
        "print(batch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.name]:('[torch.cuda.LongTensor of size 32x15 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
            "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3lNomGZSntU",
        "colab_type": "code",
        "outputId": "ca7166a4-6966-49a9-f282-0f8a0fa5ed5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "print(batch.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 2, 38,  6, 13, 57,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 27,  6,  9,  5,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 27,  6, 14,  9, 19,  3,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 40,  5, 22, 31,  4, 15,  3,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 48, 22,  7,  8,  4, 13,  4,  3,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 36,  4, 12,  4, 11,  3,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 47, 12, 14,  4,  8,  3,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 24, 21, 21,  6,  8, 21,  7,  3,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 25,  7, 30, 10, 14, 16,  3,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 38, 12,  5, 15, 12,  6,  5, 18,  3,  1,  1,  1,  1,  1],\n",
            "        [ 2, 43, 10, 10,  6, 37,  3,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 36,  6, 10,  5,  8, 22, 11,  6,  6, 17,  3,  1,  1,  1],\n",
            "        [ 2, 25,  7, 21, 12,  4, 11,  6, 18,  7, 21,  6, 18,  4,  3],\n",
            "        [ 2, 44,  4, 11,  5,  8, 16,  7, 15,  3,  1,  1,  1,  1,  1],\n",
            "        [ 2, 50, 10, 12,  7,  8,  6, 17,  6,  9,  7,  3,  1,  1,  1],\n",
            "        [ 2, 38,  6, 11,  6, 17, 22,  6,  3,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 33,  4, 11, 11, 21, 12,  6, 22, 12,  4,  9,  3,  1,  1],\n",
            "        [ 2, 23,  9,  6, 14,  9,  3,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 23, 13,  9,  6, 22,  5, 11,  3,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 40, 19, 10,  7, 12,  7,  8,  3,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 26,  6, 14, 11,  6, 10,  3,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 25,  8,  4, 13, 10,  4, 15,  4,  8, 19,  4,  8,  3,  1],\n",
            "        [ 2, 42,  5, 30, 30,  5,  9, 10,  6,  8,  3,  1,  1,  1,  1],\n",
            "        [ 2, 35,  6,  9,  9,  7,  8, 20, 13,  6,  8,  3,  1,  1,  1],\n",
            "        [ 2, 24, 11, 13,  7, 17,  4,  9,  7,  3,  1,  1,  1,  1,  1],\n",
            "        [ 2, 47,  4, 15,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 34,  4,  8,  5, 15,  3,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 42,  5, 30, 30,  9,  7,  5, 10,  3,  1,  1,  1,  1,  1],\n",
            "        [ 2, 25,  6,  9, 20,  5,  8, 10, 13,  5,  9,  8,  3,  1,  1],\n",
            "        [ 2, 29,  4, 15,  7, 17,  7,  3,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 29, 11,  4, 18, 10,  4,  3,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 27,  4, 11, 22,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1]],\n",
            "       device='cuda:0'), tensor([ 6,  6,  7,  8,  9,  7,  7,  9,  8, 10,  7, 12, 15, 10, 12,  9, 13,  7,\n",
            "         9,  9,  8, 14, 11, 12, 10,  5,  7, 10, 13,  8,  8,  6],\n",
            "       device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWaLe_26UhBQ",
        "colab_type": "text"
      },
      "source": [
        "Now, we can define our recurrent neural net for name classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Env5mIp2Tihi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KUieKPpUphz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NamesClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, input_vocab_size, output_vocab_size, num_rnn_layers=1):\n",
        "        super(NamesClassifier, self).__init__()\n",
        "        \n",
        "        # We start with a character embedding layer\n",
        "        self.emb = nn.Embedding(input_vocab_size, embedding_dim, padding_idx=NAME.vocab.stoi[\"<pad>\"])\n",
        "        # We use the GRU recurrent layer\n",
        "        # Try with LSTM instead. \n",
        "        # Also, you can experiment with bidirectional=True, but you have to multiply the input \n",
        "        # dim of the next layer with 2 then\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=False, num_layers=num_rnn_layers)\n",
        "        # Finally, we classification layer\n",
        "        self.affine = nn.Linear(hidden_dim, output_vocab_size)\n",
        "        \n",
        "    \n",
        "    def forward(self, x_in, sequence_lengths):\n",
        "        x_embedded = self.emb(x_in)\n",
        "        \n",
        "        x_post_rnn, _ = self.rnn(x_embedded)\n",
        "\n",
        "        # We take the RNN output not from the last timestep (corresponding to maximum name length of the batch\n",
        "        # but from the actual last time step of the corresponding name.\n",
        "        # It's a bit tricky :)\n",
        "        last_item_indices = sequence_lengths - 1\n",
        "        last_item_indices += torch.arange(0, x_in.size(0)).long().to(device) * x_in.size(1)\n",
        "        x_post_rnn = x_post_rnn.contiguous().to(device)\n",
        "        x_post_rnn = x_post_rnn.view(x_in.size(0) * x_in.size(1), -1)[last_item_indices]\n",
        "\n",
        "        out = self.affine(x_post_rnn)\n",
        "        return F.log_softmax(out, dim=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxZU_vnWWaz0",
        "colab_type": "text"
      },
      "source": [
        "Next, the training and evaluation loops. They are almost identical to the ones used in the last lab. The only difference is that here we also take care of sending the name lengths to the `forward()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_PV6FpcWVlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, num_epochs, train_iter, dev_iter):\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "  best_acc = 0\n",
        "  last_step = 0\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    print(\"Epoch %d\" % epoch)\n",
        "    model.train()\n",
        "    for batch in train_iter:\n",
        "      (text, text_length), target = batch.name, batch.label\n",
        "\n",
        "      # subtract one from label ID because we don't have <unk> labels\n",
        "      target -= 1\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(text, sequence_lengths=text_length)\n",
        "\n",
        "      loss = F.nll_loss(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "    train_acc = evaluate(\"train\", train_iter, model)                \n",
        "    dev_acc = evaluate(\"dev\", dev_iter, model)\n",
        "\n",
        "def evaluate(dataset_name, data_iter, model):\n",
        "  \n",
        "  model.eval()\n",
        "  total_corrects, avg_loss = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for batch in data_iter:\n",
        "      (text, text_length), target = batch.name, batch.label\n",
        "\n",
        "\n",
        "      # subtract one from label ID because we don't have <unk> labels\n",
        "      target -= 1\n",
        "      output = model(text, sequence_lengths=text_length)\n",
        "      loss = F.nll_loss(output, target, size_average=False)\n",
        "      pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "      correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "      avg_loss += loss\n",
        "      total_corrects += correct\n",
        "\n",
        "\n",
        "  size = len(data_iter.dataset)\n",
        "  avg_loss /= size\n",
        "  accuracy = 100.0 * total_corrects/size\n",
        "  print('  Evaluation on {} - loss: {:.6f}  acc: {:.4f}%({}/{})'.format(dataset_name,\n",
        "                                                                     avg_loss, \n",
        "                                                                     accuracy, \n",
        "                                                                     total_corrects, \n",
        "                                                                     size))\n",
        "  return accuracy                \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAIWkX39Wy_v",
        "colab_type": "text"
      },
      "source": [
        "Now we can train our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrVzcluyW3wf",
        "colab_type": "code",
        "outputId": "27c26f6d-db96-420f-9aff-ba2a86e7652f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model = NamesClassifier(100, 100, len(NAME.vocab), len(LABEL.vocab) - 1, num_rnn_layers=1).to(device)\n",
        "train(model, 10, train_iter, test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Evaluation on train - loss: 1.171059  acc: 67.1526%(5528/8232)\n",
            "  Evaluation on dev - loss: 1.208234  acc: 66.2782%(1820/2746)\n",
            "Epoch 2\n",
            "  Evaluation on train - loss: 0.930593  acc: 72.4733%(5966/8232)\n",
            "  Evaluation on dev - loss: 1.013790  acc: 70.5390%(1937/2746)\n",
            "Epoch 3\n",
            "  Evaluation on train - loss: 0.777180  acc: 76.6642%(6311/8232)\n",
            "  Evaluation on dev - loss: 0.897149  acc: 73.7800%(2026/2746)\n",
            "Epoch 4\n",
            "  Evaluation on train - loss: 0.665004  acc: 79.6890%(6560/8232)\n",
            "  Evaluation on dev - loss: 0.841849  acc: 75.4552%(2072/2746)\n",
            "Epoch 5\n",
            "  Evaluation on train - loss: 0.590366  acc: 82.3494%(6779/8232)\n",
            "  Evaluation on dev - loss: 0.812068  acc: 74.9454%(2058/2746)\n",
            "Epoch 6\n",
            "  Evaluation on train - loss: 0.505958  acc: 84.8518%(6985/8232)\n",
            "  Evaluation on dev - loss: 0.780005  acc: 76.8390%(2110/2746)\n",
            "Epoch 7\n",
            "  Evaluation on train - loss: 0.460340  acc: 85.8722%(7069/8232)\n",
            "  Evaluation on dev - loss: 0.787504  acc: 76.7662%(2108/2746)\n",
            "Epoch 8\n",
            "  Evaluation on train - loss: 0.405871  acc: 87.7915%(7227/8232)\n",
            "  Evaluation on dev - loss: 0.796759  acc: 76.6570%(2105/2746)\n",
            "Epoch 9\n",
            "  Evaluation on train - loss: 0.365054  acc: 89.2493%(7347/8232)\n",
            "  Evaluation on dev - loss: 0.807109  acc: 76.2928%(2095/2746)\n",
            "Epoch 10\n",
            "  Evaluation on train - loss: 0.318355  acc: 90.3669%(7439/8232)\n",
            "  Evaluation on dev - loss: 0.820625  acc: 77.1668%(2119/2746)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0s-zeFhXXCy_",
        "colab_type": "text"
      },
      "source": [
        "OK, so the accuracy of the model on test data is as above. \n",
        "\n",
        "Experiment with hypeparameters (embedding size, number of units in the hidden RNN layer, number of RNN layers, etc), try adding dropout and see if you can increase the accuracy.\n",
        "\n",
        "It would be also nice if we could apply the trained model on new data, on case-by-case basis, so that we could play with the model. Let's do that.\n",
        "\n",
        "First, we have to convert the user-given name to a tensor. We can use the `process()` method of the corresponding field for that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLyiC6EFW6Z1",
        "colab_type": "code",
        "outputId": "af430680-733a-480b-c65f-a63aaaad501e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(NAME.process([\"Alum√§e\"], device=device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[ 2, 24, 11, 14, 17, 59,  5,  3]], device='cuda:0'), tensor([8], device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHUVVBWkYK3u",
        "colab_type": "text"
      },
      "source": [
        "Now, creating the a nice classify function is easy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAwjr3cDYBSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(model, name):\n",
        "  name_var, length_var = NAME.process([name], device=device)\n",
        "  logit = model(name_var, sequence_lengths=length_var)\n",
        "  # Select the index with the maximum value\n",
        "  predicted_label_id = torch.argmax(logit, dim=1).item()\n",
        "  # Add 1 to the index before looking up the corresponding label (because of the <unk> thing)\n",
        "  return LABEL.vocab.itos[predicted_label_id + 1]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiXyx5NJZH3h",
        "colab_type": "text"
      },
      "source": [
        "Remember, our model only recognizes the nationalities that are in its label vocabulary. All names will be mapped to one of them. And of course, the model makes mistakes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCXMjgouZSf9",
        "colab_type": "code",
        "outputId": "a2df6a12-19b4-40f9-fca4-74b135b22878",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "LABEL.vocab.itos"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " 'English',\n",
              " 'Russian',\n",
              " 'Arabic',\n",
              " 'Japanese',\n",
              " 'German',\n",
              " 'Italian',\n",
              " 'Czech',\n",
              " 'Spanish',\n",
              " 'Dutch',\n",
              " 'French',\n",
              " 'Chinese',\n",
              " 'Irish',\n",
              " 'Greek',\n",
              " 'Polish',\n",
              " 'Korean',\n",
              " 'Scottish',\n",
              " 'Vietnamese',\n",
              " 'Portuguese']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g121B_ebYpuW",
        "colab_type": "code",
        "outputId": "1b939d30-3c1f-4830-c1c6-3ced451b188b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Trump\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'English'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADWiYDduYsJj",
        "colab_type": "code",
        "outputId": "2f0c8d53-fa29-450b-d076-333d784e4c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Putin\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Russian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QKk9odzYt3L",
        "colab_type": "code",
        "outputId": "ce45e2fd-8e5e-4a8c-b3a4-de8447207aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Merkel\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'German'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0LIqsFiYvOP",
        "colab_type": "code",
        "outputId": "c0408dc2-cbfe-4a76-93d8-4d91a514fb3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Macron\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'English'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOiobi61Ywnj",
        "colab_type": "code",
        "outputId": "70ac42a7-3a16-4311-97c2-b353a0b567b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Berlusconi\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Italian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H_nnQQCYzO7",
        "colab_type": "code",
        "outputId": "0ce893ff-ed03-41b1-9a86-219e4e8cde4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Ronaldo\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Italian'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQPuQDzRY1XW",
        "colab_type": "code",
        "outputId": "7efefac3-73bd-4f0b-a93c-4775fe2c36fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Neumannova\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Czech'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7NWrpVgY4JL",
        "colab_type": "code",
        "outputId": "678c44e1-ce9a-45f3-c042-fe59ca813c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Panathinaikos\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Greek'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE89bVkLZqYN",
        "colab_type": "code",
        "outputId": "0dd181a0-6250-44a4-cdfc-1a81d507d3fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classify(model, \"Minh\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Vietnamese'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMiTRjIlZygT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}