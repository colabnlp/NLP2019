{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab08b.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaver/NLP2019/blob/master/Lab08b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T8xkQ1dMeYv",
        "colab_type": "text"
      },
      "source": [
        "# Using and training word embeddings for simple named entity recognition\n",
        "\n",
        "In this lab, we will train a simple feed-forward Pytorch neural network to to nmed entity recognition. We will use the same dataset as a few weeks ago.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nqq9cNlNFMw",
        "colab_type": "text"
      },
      "source": [
        "Now, let's import some packages that we will later need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2WxOyT0JPKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oarn4AxuNLOt",
        "colab_type": "text"
      },
      "source": [
        "Let's also download and read the NER train and dev data. We use the same functions as a few weeks ago."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ZpKWN7OsCt",
        "colab_type": "code",
        "outputId": "6300bc42-27ff-41ee-d1ee-6bc62610d302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-19 11:06:29--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3281528 (3.1M) [text/plain]\n",
            "Saving to: ‘eng.train’\n",
            "\n",
            "eng.train           100%[===================>]   3.13M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-19 11:06:32 (30.5 MB/s) - ‘eng.train’ saved [3281528/3281528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juVHiSZKYmt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnf-Thx_Ypu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain, groupby\n",
        "def read_conll(filename):  \n",
        "    result = []\n",
        "    f = open(filename)\n",
        "    lines = (str.strip(line) for line in  f)\n",
        "    groups = (grp for nonempty, grp in groupby(lines, bool) if nonempty)\n",
        "\n",
        "    for group in groups:\n",
        "        group = list(group)\n",
        "\n",
        "        obs, lbl = zip(*(ln.rsplit(None, 1) for ln in group))\n",
        "        lbl = [l.lstrip(\"B-\").lstrip(\"I-\") for l in lbl]\n",
        "        word = [x.split()[0] for x in obs]\n",
        "\n",
        "        result.append(list(zip(word, lbl)))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux62Iwl-YtNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = read_conll(\"eng.train\")\n",
        "dev_data = read_conll(\"eng.testa\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8qh12T1NWPO",
        "colab_type": "text"
      },
      "source": [
        "Now, we will construct the vocabulary of words that the model knows about. We use all words that occur in training data at least twice. All other words are mapped to special word `<unk>`.\n",
        "\n",
        "Each word is associated with an integer (the ID of the word).\n",
        "\n",
        "Also, each output label is associated with an integer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhdBrBL5d3iI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "word_counter = Counter()\n",
        "for sentence in train_data:\n",
        "  for word, label in sentence:\n",
        "    word_counter[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZZdeXj6eF_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = {}\n",
        "vocabulary[\"<unk>\"] = 0\n",
        "vocabulary[\"<s>\"] = 1\n",
        "vocabulary[\"</s>\"] = 2\n",
        "for word in word_counter:\n",
        "  if word_counter[word] > 1:\n",
        "    vocabulary[word] = len(vocabulary)\n",
        "    \n",
        "label_vocabulary = {}\n",
        "label_vocabulary[\"O\"] = 0\n",
        "label_vocabulary[\"ORG\"] = 1\n",
        "label_vocabulary[\"LOC\"] = 2\n",
        "label_vocabulary[\"MISC\"] = 3\n",
        "label_vocabulary[\"PER\"] = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH35Qvr7OM9I",
        "colab_type": "text"
      },
      "source": [
        "Now, we will convert our training data to a form needed by Pytorch. For this, we have to inherit Pytorch Dataset class and implement a few methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sLOh-9fe-LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class NERDataset(Dataset):\n",
        "    \"\"\"Name Classification dataset\"\"\"\n",
        "\n",
        "    def __init__(self, data ):\n",
        "        items = []\n",
        "        labels = []\n",
        "        for sentence in data:\n",
        "          for i in range(len(sentence)):\n",
        "            if i > 0:\n",
        "              prevw = vocabulary.get(sentence[i-1][0], 0)\n",
        "            else:\n",
        "              prevw = vocabulary[\"<s>\"]\n",
        "            if i+1 < len(sentence):\n",
        "              nextw = vocabulary.get(sentence[i+1][0], 0)\n",
        "            else:\n",
        "              nextw = vocabulary[\"</s>\"]\n",
        "            items.append((prevw, vocabulary.get(sentence[i][0], 0), nextw))\n",
        "            labels.append(label_vocabulary[sentence[i][1]])\n",
        "        self.X = torch.from_numpy(np.array(items).astype(int)).long()\n",
        "        self.y = torch.from_numpy(np.array(labels).astype(int)).long()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        sample = {'X': X, 'y': y}\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT5YHlEdifmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = NERDataset(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M9haushvJO8",
        "colab_type": "text"
      },
      "source": [
        "The `train_dataset` variable now holds actual training examples that we'll feed to the neural net during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-Wxe8hdjE6h",
        "colab_type": "code",
        "outputId": "db4dddbd-b381-43f5-f353-72f19533b7fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_dataset[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'X': tensor([ 1, 12, 13]), 'y': tensor(4)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ujmXTNOVTh",
        "colab_type": "text"
      },
      "source": [
        "Now, we will define our model. It inherits from Pytorch nn.Module. \n",
        "\n",
        "The model first projects the three words in our data (prev, current, next) to vector space, using the special `Embedding` class. Embeddings are concatenated, and passed through an affine (linear) layer, with a ReLU non-linearity. The output goes to softmax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj9x4V-3jrv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NERNN(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
        "        super(NERNN, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.fc1 = nn.Linear(embedding_dim * 3, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x).view(-1, (embedding_dim * 3))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig5HydhFPETY",
        "colab_type": "text"
      },
      "source": [
        "Next, we will implement our training loop. It loops through minibatches. For each minibatch, it computes the outputs of the model with regard of the inputs, calculates the loss w.r.t to the real targets, computes gradients via backpropagation, and updates the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3d_qE8kk0IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataloader, num_epochs):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    \n",
        "    if cuda:\n",
        "        model.cuda()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    loss_function = nn.NLLLoss()\n",
        "    loss_history = []\n",
        "    for i in range(num_epochs):\n",
        "        for batch in dataloader:\n",
        "            model.zero_grad()\n",
        "            X = batch['X']\n",
        "            \n",
        "            y = batch['y']\n",
        "            if cuda:\n",
        "                X = X.cuda()\n",
        "                y = y.cuda()\n",
        "            outputs = model(X)\n",
        "            loss = loss_function(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        loss_history.append(loss.item())\n",
        "        print('epoch[%d] log loss: %.4f' % (i, loss.item()))\n",
        "    return loss_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8T7ZyFqPbdF",
        "colab_type": "text"
      },
      "source": [
        "Now, we can create our model, with some (randomly selected) hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNLHCFbak34m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(vocabulary)\n",
        "embedding_dim = 50 # dimensionality of word embeddings\n",
        "hidden_dim = 100   # dim of hidden layer\n",
        "output_size = len(label_vocabulary) # number of classes\n",
        "\n",
        "\n",
        "model = NERNN(vocab_size, embedding_dim, hidden_dim, output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD9F_kfAPkI7",
        "colab_type": "text"
      },
      "source": [
        "When training, we have to wrap our data using DataLoader, which shuffles our data and splits it into minibatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t98o_lDwlW_F",
        "colab_type": "code",
        "outputId": "f78e47c7-f889-423a-ba0c-8513e18ae9a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "loss_history = train(model, train_dataloader, 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[0] log loss: 0.1536\n",
            "epoch[1] log loss: 0.1693\n",
            "epoch[2] log loss: 0.1035\n",
            "epoch[3] log loss: 0.0043\n",
            "epoch[4] log loss: 0.0047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7L1DSA4P3B0",
        "colab_type": "text"
      },
      "source": [
        "Alright, the model is trained!\n",
        "\n",
        "Let's plot our training loss values thoughout the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ctdV7xqGsIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iadU8jyVHkSF",
        "colab_type": "code",
        "outputId": "66a71910-c5e1-47e0-e36b-481ba08212fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.plot(loss_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fef5f06f048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD5CAYAAADLL+UrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyKSQlT6IiIp5P8DjjV6BKczEaAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wByavv1fQDJ2",
        "colab_type": "text"
      },
      "source": [
        "The following part applies the model to dev data and calculates the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OlnxCQ1Hp_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_dataset = NERDataset(dev_data)\n",
        "dev_dataloader = DataLoader(dev_dataset, batch_size=32, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XViuHxz1LIgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, dataloader):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    ground_truth = []\n",
        "    predictions = []\n",
        "    for batch in dataloader:\n",
        "        X = batch['X']\n",
        "        y = batch['y']\n",
        "        if cuda:\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "        outputs = model(X)\n",
        "        _, y_preds = torch.max(outputs, dim=1)\n",
        "        ground_truth.append(y.data.cpu().numpy())\n",
        "        predictions.append(y_preds.data.cpu().squeeze().numpy())\n",
        "    return np.concatenate(ground_truth), np.concatenate(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW-ssm6wLWgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ground_truth, predictions = predict(model, dev_dataloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGOGRngwLn7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdQIOJpHL5KS",
        "colab_type": "code",
        "outputId": "741ade4a-7eba-493f-feb5-6867a50eb14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(accuracy_score(ground_truth, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9557951064407305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4qDH2dBL8DB",
        "colab_type": "code",
        "outputId": "b5163ac3-3da7-444e-d904-79192134e39c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "sns.heatmap(confusion_matrix(ground_truth, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef5a700240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWkAAAD4CAYAAAAuNhccAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmElakhrMJC1JDWaSlqQG+z+ayKkiM1v64wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWMIhQoeouLy",
        "colab_type": "text"
      },
      "source": [
        "# Using pretrained embeddings\n",
        "Next, we try to use pretrained word embeddings, instead of training them from scratch.\n",
        "\n",
        "We will use the gensim package for reading the pretrained Engish embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CYxnKCXo4hT",
        "colab_type": "code",
        "outputId": "bada9ae6-f9e6-43a7-aaaa-7373c2d57c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "!pip install gensim\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.113)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.113 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.113)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.113->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.113->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vPRJDJxpM48",
        "colab_type": "code",
        "outputId": "51b0b3c0-6bdb-40cf-8f63-6bbd75c5f3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "!wget --no-check-certificate https://phon.ioc.ee/~tanela/tmp/glove.6B.50d.w2vformat.txt.gz\n",
        "!gunzip glove.6B.50d.w2vformat.txt.gz\n",
        "wv_en =  KeyedVectors.load_word2vec_format(\"glove.6B.50d.w2vformat.txt\", binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-19 11:11:43--  https://phon.ioc.ee/~tanela/tmp/glove.6B.50d.w2vformat.txt.gz\n",
            "Resolving phon.ioc.ee (phon.ioc.ee)... 193.40.251.126\n",
            "Connecting to phon.ioc.ee (phon.ioc.ee)|193.40.251.126|:443... connected.\n",
            "WARNING: cannot verify phon.ioc.ee's certificate, issued by ‘CN=TERENA SSL CA 3,O=TERENA,L=Amsterdam,ST=Noord-Holland,C=NL’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69182535 (66M) [application/x-gzip]\n",
            "Saving to: ‘glove.6B.50d.w2vformat.txt.gz’\n",
            "\n",
            "glove.6B.50d.w2vfor 100%[===================>]  65.98M  7.50MB/s    in 29s     \n",
            "\n",
            "2019-03-19 11:12:14 (2.27 MB/s) - ‘glove.6B.50d.w2vformat.txt.gz’ saved [69182535/69182535]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5RcKGiWpTY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0rTY1DBpfdG",
        "colab_type": "text"
      },
      "source": [
        "The wv_en variable is now a gensim object that holds pretrained embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKHLuY4MpmkG",
        "colab_type": "code",
        "outputId": "2ccc8adf-976d-4355-ed2b-9856f9a6f56b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "wv_en.most_similar(\"horse\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('horses', 0.8595937490463257),\n",
              " ('dog', 0.7907582521438599),\n",
              " ('riding', 0.7717962861061096),\n",
              " ('bull', 0.7642240524291992),\n",
              " ('breeders', 0.7027289867401123),\n",
              " ('cat', 0.7017536759376526),\n",
              " ('derby', 0.6957983374595642),\n",
              " ('ride', 0.6939681172370911),\n",
              " ('camel', 0.6921409964561462),\n",
              " ('bike', 0.6891596913337708)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Ki3p1CpxxV",
        "colab_type": "text"
      },
      "source": [
        "We will now have to pre-fill the embeddings matrix with the pre-trained  embeddings. For this we have to map the word IDs to correct positions.\n",
        "\n",
        "Special care has to be taken for unknown words (words in our data but not in the pretrained vocabulary) and the special tokens that we use in our model. \n",
        "\n",
        "We let the embeddings of unknown words to be all-zero, and the embeddings of `<s>` and `</s>` we'll fill with -1 and 1, respectively. This is a rather heuristic decision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U7aB6C4qQmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_embeddings = torch.FloatTensor(len(vocabulary), wv_en.vector_size)\n",
        "for word in vocabulary:\n",
        "  if word.lower() in wv_en:\n",
        "    pretrained_embeddings[vocabulary[word]] = torch.from_numpy(wv_en[word.lower()])\n",
        "\n",
        "pretrained_embeddings[vocabulary[\"<s>\"]] = -1\n",
        "pretrained_embeddings[vocabulary[\"</s>\"]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ3oWJJyuATJ",
        "colab_type": "text"
      },
      "source": [
        "Now we will define our model that uses pretrained embeddings. Note how the pretrained embeddings are now given in the consstructor, and they are used to initialize the weights of the embeddings.\n",
        "\n",
        "We also add another parameter, `train_embeddings`, that says whether we want the embeddings to be updated during training or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loT53V6pqgFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NERNN_pretrained_embeddings(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, hidden_dim, output_size, pretrained_embeddings, train_embeddings=True):\n",
        "        super(NERNN_pretrained_embeddings, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, pretrained_embeddings.shape[1], padding_idx=0)\n",
        "        self.embeddings.weight = nn.Parameter(pretrained_embeddings)\n",
        "        self.embeddings.weight.requires_grad = train_embeddings\n",
        "        \n",
        "        self.fc1 = nn.Linear(embedding_dim * 3, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x).view(-1, (embedding_dim * 3))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwupfP9Tr2He",
        "colab_type": "text"
      },
      "source": [
        "We also have to redefine the train function, so that the optimizer won't try to update the embeddings if we don't want it. Note the lambda in the Adam constructor: it tells the optimizer not to optimize the parameters that have the `requires_grad` attribute set to `False`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJtDA4WesPgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, dataloader, num_epochs):\n",
        "    cuda = torch.cuda.is_available()\n",
        "    \n",
        "    if cuda:\n",
        "        model.cuda()\n",
        "    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "    loss_function = nn.NLLLoss()\n",
        "    loss_history = []\n",
        "    for i in range(num_epochs):\n",
        "        for batch in dataloader:\n",
        "            model.zero_grad()\n",
        "            X = batch['X']\n",
        "            \n",
        "            y = batch['y']\n",
        "            if cuda:\n",
        "                X = X.cuda()\n",
        "                y = y.cuda()\n",
        "            outputs = model(X)\n",
        "            loss = loss_function(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        loss_history.append(loss.data.item())\n",
        "        print('epoch[%d] log loss: %.4f' % (i, loss.data.item()))\n",
        "    return loss_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJVgJSZOsYdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = NERNN_pretrained_embeddings(vocab_size, hidden_dim, output_size, pretrained_embeddings, train_embeddings=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZcPIb40smTj",
        "colab_type": "code",
        "outputId": "57fb1fdc-f47e-43cb-ca16-3c22d3928b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "loss_history = train(model2, train_dataloader, 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[0] log loss: 0.0482\n",
            "epoch[1] log loss: 0.0157\n",
            "epoch[2] log loss: 0.0113\n",
            "epoch[3] log loss: 0.0186\n",
            "epoch[4] log loss: 0.0454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD8r9RFystiB",
        "colab_type": "code",
        "outputId": "19799dce-77f2-4f73-ec54-f2070e93353a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ground_truth, predictions = predict(model2, dev_dataloader)\n",
        "print(accuracy_score(ground_truth, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.945480631276901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG5JBQFxs8H1",
        "colab_type": "text"
      },
      "source": [
        "OK, so using the pretrained embeddings didn't really help, but look at how the value of the loss function was quite low already after the 1st epoch.\n",
        "\n",
        "Let's now train a third model, but now we'll use pretrained embeddings, but we allow the embeddings to be updated during training. Thereby, we hope that the embeddings are adapted to our task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjGup2ODtYZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model3 = NERNN_pretrained_embeddings(vocab_size, hidden_dim, output_size, pretrained_embeddings, train_embeddings=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32LrTJDOtbGl",
        "colab_type": "code",
        "outputId": "a25ea888-a3b6-4257-b29e-2429ac64200d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "loss_history = train(model3, train_dataloader, 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch[0] log loss: 0.0022\n",
            "epoch[1] log loss: 0.0328\n",
            "epoch[2] log loss: 0.0916\n",
            "epoch[3] log loss: 0.0101\n",
            "epoch[4] log loss: 0.1650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCNBNpy3te4-",
        "colab_type": "code",
        "outputId": "13572764-86df-4904-d665-006fc8ed1068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ground_truth, predictions = predict(model3, dev_dataloader)\n",
        "print(accuracy_score(ground_truth, predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9651013998216293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX0zXY6htpgh",
        "colab_type": "text"
      },
      "source": [
        "Alright, adapting the pretrained embeddings gave us better accuracy! I don't really know why the value of the loss function fluctuates so much during training."
      ]
    }
  ]
}