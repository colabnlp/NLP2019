{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab12_2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaver/NLP2019/blob/master/Lab12_2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1xOZ9jsVgk6",
        "colab_type": "text"
      },
      "source": [
        "This notebook shows how to do conditional generation using an RNN. \n",
        "\n",
        "The model learns to generate male and female names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa_m8yJy5tXQ",
        "colab_type": "code",
        "outputId": "b464d68f-a783-45e0-d7ea-6228868508c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch \n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyZpaJMn9dsX",
        "colab_type": "text"
      },
      "source": [
        "As training data, we use the starting list of the 2010 Tartu Maraton (cross-country ski marathon)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgT9yCzmKtYz",
        "colab_type": "code",
        "outputId": "e0c5236b-6292-4882-ff68-267863597316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "! rm -f tm2010_names_with_gender.csv\n",
        "!wget https://phon.ioc.ee/~tanela/tmp/tm2010_names_with_gender.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-16 06:48:50--  https://phon.ioc.ee/~tanela/tmp/tm2010_names_with_gender.csv\n",
            "Resolving phon.ioc.ee (phon.ioc.ee)... 193.40.251.126\n",
            "Connecting to phon.ioc.ee (phon.ioc.ee)|193.40.251.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88405 (86K) [text/csv]\n",
            "Saving to: ‘tm2010_names_with_gender.csv’\n",
            "\n",
            "tm2010_names_with_g 100%[===================>]  86.33K   158KB/s    in 0.5s    \n",
            "\n",
            "2019-04-16 06:48:52 (158 KB/s) - ‘tm2010_names_with_gender.csv’ saved [88405/88405]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLIFApKqVxKz",
        "colab_type": "code",
        "outputId": "73bd69b3-745c-4f45-9bf9-b8243abe0d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head tm2010_names_with_gender.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Aukland, Anders\",M\n",
            "\"Brink, Joergen\",M\n",
            "\"Svaerd, Oskar\",M\n",
            "\"Rezac, Stanislav\",M\n",
            "\"Fredriksson, Mathias\",M\n",
            "\"Larsson, Martin\",M\n",
            "\"Sinnes, Svein Tore\",M\n",
            "\"Narusk, Priit\",M\n",
            "\"Veerpalu, Andrus\",M\n",
            "\"Jaernberg, Anton\",M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AST9qMjmLQzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from torchtext import data\n",
        "from torchtext import datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u-_qV5MK-gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = data.Field(tokenize=list, init_token=\"<bos>\", eos_token=\"<eos>\",  batch_first=True)\n",
        "GENDER = data.Field(sequential=False)\n",
        "text_dataset_with_gender = data.TabularDataset(path='tm2010_names_with_gender.csv', \\\n",
        "                                               format='csv', \\\n",
        "                                               fields=[('text', TEXT), ('gender', GENDER)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWll5nGy9lLv",
        "colab_type": "code",
        "outputId": "6e81faae-0d40-43f9-c166-f4ae488e652e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(text_dataset_with_gender))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dExLKQCmLKoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(text_dataset_with_gender)\n",
        "GENDER.build_vocab(text_dataset_with_gender)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJWtwVXrLf1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_iter_with_gender = data.BucketIterator(text_dataset_with_gender, batch_size=32,  device=device, repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUdtDA369zsW",
        "colab_type": "code",
        "outputId": "33e759f0-6039-40ed-d0e7-2ae98593912a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(next(iter(text_iter_with_gender)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.text]:[torch.cuda.LongTensor of size 32x20 (GPU 0)]\n",
            "\t[.gender]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SsSErpoLljk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lu3xuYMrMJpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharGenderNN(nn.Module):\n",
        "    def __init__(self, embedding_dim,  hidden_dim, vocab_size, num_rnn_layers=1):\n",
        "        super(CharGenderNN, self).__init__()\n",
        "        \n",
        "        self.emb = nn.Embedding(vocab_size, embedding_dim, padding_idx=TEXT.vocab.stoi[\"<pad>\"])\n",
        "        # The gender embeddings need to be of the same dimensionality as the \n",
        "        # hidden state of the GRU, as we need to have initial state for all\n",
        "        # GRU layers.\n",
        "        self.gender_emb = nn.Embedding(2, hidden_dim * num_rnn_layers)\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, batch_first=True, num_layers=num_rnn_layers)\n",
        "        self.affine = nn.Linear(hidden_dim, vocab_size)\n",
        "        \n",
        "             \n",
        "    def forward(self, x_in, gender_in, hidden=None, return_with_hidden=False):\n",
        "        x_embedded = self.emb(x_in)\n",
        "        \n",
        "        if hidden is None:\n",
        "            # If hidden state is not given, we'll use the embedding of the\n",
        "            # given gender as the initial hidden state\n",
        "            g_embedded = self.gender_emb(gender_in)            \n",
        "            hidden = g_embedded.view(x_in.shape[0], self.rnn.num_layers, self.rnn.hidden_size).permute(1,0,2)\n",
        "            \n",
        "        x_post_rnn, hidden = self.rnn(x_embedded, hidden)\n",
        "        out = self.affine(x_post_rnn)\n",
        "        if return_with_hidden:\n",
        "            return out, hidden\n",
        "        else:\n",
        "            return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gQ0UZeM95x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_generator_model_with_gender = CharGenderNN(100, 200, len(TEXT.vocab), num_rnn_layers=1).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSu02J_iNa9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_text_generator_with_gender(model, num_epochs, text_iter, log_interval=10):\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "  steps = 0\n",
        "  best_acc = 0\n",
        "  last_step = 0\n",
        "  model.train()\n",
        "  for epoch in range(1, num_epochs+1):\n",
        "    for batch in text_iter:\n",
        "      text = batch.text\n",
        "      gender = batch.gender\n",
        "      # subtract 1 to account for the unused <unk> class\n",
        "      gender -= 1\n",
        "      # The model predicts the next character from the previous characters\n",
        "      # So, the target characters are same as source characters, but shifted to \n",
        "      # the right by one\n",
        "      input_text = text[:, :-1]\n",
        "      target = text[:, 1:]\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      logit = model(input_text, gender)\n",
        "      # We need to re-organize the axes of the returned logits (unnormalized probabilities)\n",
        "      # because the cross_entropy() wants the probabilities always be in the 2nd dimension\n",
        "      # See http://pytorch.org/docs/master/nn.html#torch.nn.CrossEntropyLoss\n",
        "      loss = F.cross_entropy(logit.permute(0,2,1), target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      steps += 1\n",
        "      if steps % log_interval == 0:\n",
        "        sys.stdout.write('\\rEpoch: {} batch[{}] - loss: {:.6f})'.format(epoch, steps, \n",
        "                                                                     loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuXc-S7zNldg",
        "colab_type": "code",
        "outputId": "7196b80f-54e8-4269-f4f3-94e9111a7f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_text_generator_with_gender(text_generator_model_with_gender, 30, text_iter_with_gender)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30 batch[4500] - loss: 0.829197)"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0XtRhf7PEiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_from_with_gender(model, gender, temperature=1.0, n_length=30, burn=0):\n",
        "    result = []\n",
        "    # The first character is fixed -- it's our beginning-of-sentence character\n",
        "    in_var = torch.LongTensor([[TEXT.vocab.stoi[\"<bos>\"]]]).to(device)\n",
        "    # At the beginning, the hidden state of the RNN is unset\n",
        "    hx = None\n",
        "    gender_var = torch.LongTensor([GENDER.vocab.stoi[gender] - 1]).to(device)\n",
        "    for _ in range(n_length):\n",
        "        # Get the prediction and the hidden state, based on the input\n",
        "        y_pred, hx = model(in_var, gender_var, hidden=hx, return_with_hidden=True)\n",
        "        # Normalize the predictions\n",
        "        y_pred = torch.nn.functional.softmax(y_pred/temperature, dim=2)\n",
        "        # Sample from the generated distribition\n",
        "        # The prediction occupy the last dimension or y_pred, so we sample\n",
        "        # over the last (-1) dimension\n",
        "        in_var = torch.multinomial(y_pred.view(y_pred.shape[-1]), num_samples=1).view(1,1)\n",
        "\n",
        "        # If you want to take the most likely character (not sample it), then use this instead\n",
        "        # This way we will decode using greedy search\n",
        "        # Of course, this will generate the same name every time\n",
        "        #in_var = torch.argmax(y_pred.view(y_pred.shape[-1])).view(1,1)\n",
        "        \n",
        "        # If the sampled character is the end-of-sentence character, then we'll stop\n",
        "        if in_var.data[0,0] == TEXT.vocab.stoi[\"<eos>\"]:\n",
        "          break\n",
        "        result += [TEXT.vocab.itos[in_var.data[0,0]]]\n",
        "    # Convert list of characters to string\n",
        "    return \"\".join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb1tQZHtPbfr",
        "colab_type": "code",
        "outputId": "ad0d1e58-dccf-4f00-e911-1c074bbc5070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample_from_with_gender(text_generator_model_with_gender, 'N'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Riissoo, Sirije\n",
            "Veide, Margit\n",
            "Müüna, Anne\n",
            "Rang, Aige\n",
            "Talve, Anne\n",
            "Batoja, Kristi\n",
            "Veskäorf, Katrin\n",
            "Roetelian, Jen-Eiko\n",
            "Karula, Heidi\n",
            "Praos, Maija\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tgy6MvlQp6y",
        "colab_type": "code",
        "outputId": "078251de-eb48-426c-800c-d2f7a83d8c8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "for i in range(10):\n",
        "  print(sample_from_with_gender(text_generator_model_with_gender, 'M'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avazcilt, Kert\n",
            "Kanniste, Riho\n",
            "Reitonen, Mikko\n",
            "Murandey, Fiemet\n",
            "Tõnster, Kerti\n",
            "Palomägi, Tauno\n",
            "Tarla, Toomas\n",
            "Firnik, William\n",
            "Perno, Indrek\n",
            "Lääkamäe, Jannar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbGdDGGK6lSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}