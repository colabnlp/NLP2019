{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab02_2019.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akaver/NLP2019/blob/master/Lab02_2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyCOqcSIR6em",
        "colab_type": "text"
      },
      "source": [
        "This lab assumes that the student has basic knowledge of Python. If not, please go to http://www.learnpython.org and go through the interactive tutorials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDb_VhCVR6eo",
        "colab_type": "text"
      },
      "source": [
        "## Reading files using a specified codec\n",
        "\n",
        "First, we'll study how to read content from text file. \n",
        "\n",
        "We learned in the lecture that it's important to know the text codec that is used to encode the characters, when reading text from files. This can be done using the codecs package.\n",
        "\n",
        "You can the sample text from here: http://www.phon.ioc.ee/~tanela/parasiitlusest.txt but you are encourage to use any other Estonian text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9z3N8sWSD0S",
        "colab_type": "code",
        "outputId": "cbf2a4b1-e785-4df7-8bca-232df4f49a16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "!wget http://www.phon.ioc.ee/~tanela/parasiitlusest.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-05 10:56:06--  http://www.phon.ioc.ee/~tanela/parasiitlusest.txt\n",
            "Resolving www.phon.ioc.ee (www.phon.ioc.ee)... 193.40.251.126\n",
            "Connecting to www.phon.ioc.ee (www.phon.ioc.ee)|193.40.251.126|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://phon.ioc.ee/~tanela/parasiitlusest.txt [following]\n",
            "--2019-02-05 10:56:06--  https://phon.ioc.ee/~tanela/parasiitlusest.txt\n",
            "Resolving phon.ioc.ee (phon.ioc.ee)... 193.40.251.126\n",
            "Connecting to phon.ioc.ee (phon.ioc.ee)|193.40.251.126|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496 (4.4K) [text/plain]\n",
            "Saving to: ‘parasiitlusest.txt’\n",
            "\n",
            "parasiitlusest.txt  100%[===================>]   4.39K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-05 10:56:07 (62.5 MB/s) - ‘parasiitlusest.txt’ saved [4496/4496]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2asl5Zw5R6ep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import codecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LFDOHLHR6eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = codecs.open('parasiitlusest.txt', 'r', 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OYrLbHiR6ey",
        "colab_type": "text"
      },
      "source": [
        "The arguments correspond to file name, mode ('r' stands for 'read'), and the codec.\n",
        "\n",
        "The returned variable `f` is a file handle. It doesn't contain the file contents, it's just a link to the file in the filesystem.\n",
        "\n",
        "There are a number of ways to read the text from the text file. One of the simplest is the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaDkfHdJR6e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-VI_HkHR6e4",
        "colab_type": "code",
        "outputId": "56e066a7-28b5-4521-82c1-4233797272d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(lines)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Parasiitlus on teiste energiast toitumine ilma, et midagi samaväärset vastu antaks ehk saamahimu üks väljendusvorme. Parasiitluse vastand on taimeriigis levinud sümbioos (botaanikas tuntud mõiste), kus toimub vastastikku kasulik kaubavahetus.\\r\\n', 'Parasiitlus on hingestatud isikutele paratamatu ehk ülivajalik õppetund, mis hakkab pihta juba ainuraksetel loomadel viiruste ja bakterite näol ja maise inimhinge tasandil lõpeb paralleelmaailmade valgete draakonite (kõrgtasandi reptiloidide = keha + mõistus, hing puudub) pakutavate manipulatsioonide tundmaõppimisega.\\r\\n', 'Selleks et õppetund oleks täiuslik, korraldab elu olukorrad, kus ollakse kord ise parasiit, kord ollakse parasiidi ohver. Kuni inimeses on tahtmine teiste seljas liugu lasta, tõmbab ta endale ligi (vastavalt magnetismi seadusele) parasiite, kannatades ise ja pannes teisi kannatama. Õppetunni lõppeesmärgina peab inimene teadvustama, et ta teadlikult tasakaalustab saadu millegi sama väärtuslikuga.\\r\\n', 'Parasiitluse üks erivorme on vampiirlus, kus energia imemine toimub füüsilist kontakti omamata, kasutades selleks peenmateriaalseid struktuure. Ainuke abi vampiirile on mitte lasta tal teie üle võimutseda – et ta õpiks ise energiat tootma. Vampiir on läinud elus lihtsama vastupanu teed. Selle asemel, et ise energiat toota või tootmisprotsessis osaleda, on ta teinud otsuse talle vajalikku energia varastada. Lihtsama vastupanu teed minemine on alati raskem tee. Sellel lihtsal põhjusel, et endale võetud õppetunnid tuleb omandada niikuinii pluss katsumused, mis saadakse sellel nn. lihtsal teel. Sellest momendist, kui inimene on teinud otsuse lihtsama vastupanu teed minna, hakkab ta hingel raske – ta on läinud oma südame-tunnistusega vastuollu. Südametunnistusega vastuollu minek on hinge eitamine. Seda mida pole, seda on lihtne ära anda. Seda teadmist kasutab ära orjandussüsteem, meelitades inimesi oma hingest loobuma. See, kes oma hingeosa ära on andnud, loobub paratamatult ka oma tegutsemise jõust. See, kes on jõuetu, ei suuda enam oma probleeme lahendada ehk ta on oma probleemide ees jõuetu.\\r\\n', 'Vampiir ei saa õnnelik olla, kuna ta on ennast ise loomingust välja lülitanud. Looming tähendab isetegemist ja selle kaudu oma isiksuse arendamist. Kui teistelt energiat valmiskujul võetakse, siis enda sees olevad energia tootmissüsteemid jäävad tööta ja manduvad. Mida kauem inimvampiir tegutseb, seda suuremasse sõltuvusse ta teiste inimeste energiast jääb. Lõpuks on tema eesmärgiks ja pidevaks tegutsemisliiniks probleem, kuidas teistelt energiat kätte saada. Teda ei huvita see, mis ohvrist saab – peaasi et oma eluks vajaliku portsu energiat kätte saaks. \\r\\n', 'Üks võimsamaid ja salakavalamaid vampirismisüsteeme, mille kaudu toituvad paralleelmaailmade ja dimensioonide isendid, on kõikvõimalikud religiooni-süsteemid, mis meelitavad inimesi oma mõistust eitama ja jumala ülemuslikkust tunnistama. Inimene, kes oma mõistusest  loobub  ja  teiste  oma  paremaks peab või kes alahindab oma mõistust ja sellega laseb teistel enda üle võimutseda ja lõpuks võitlusest loobub ehk võimutsejaid eitama hakkab, avab endale tee kiilaspäisusele. Inimene, kes ei julge oma saatust ehk neid õppetunde, mis ta enne kehastumist valis,  vastu võtta ja kaldub kergema vastupanu teele – selle juuksed langevad pöörise kohalt välja. Sellega jääb ta ilma (kaotab sideme) oma elutee vaimsete õpetajate juhendamisest ja elu ülendavast poolest ehk õnnest. Ta peab endale vajalikku ülendavat energiat teistelt varastama ehk teiste kallal vampiiritsema. Kui ohvrilt ülendav ehk ülestõstev energia pihta pannakse, hakkab tal füüsiliselt raske ja ta tunneb end maadligi litsutuna.\\r\\n', 'Inimene, kes kõigi teiste inimeste (rääkimata füüsilisele silmaga nähtamatute tegelaste olemasolust) vaimsust eitama hakkab, kaotab kõik juuksed. Temast on saanud puhtmaterialistliku maailmavaatega kodanik. Ta püüab teistele tõestada, et ta on hirmus vaimne. Paraku vajab tõestamist vaid see, mida pole. Kui kiilakas kirikupapp teile kõrgest jumalast lugusid pajatab, siis halenaljakamat pilti on vist raske ette kujutada. Kui minna kirikusse ja öelda, et see on üks suur kurjuse, vampiiride ja kollide pesa, siis võid suure tõenäosusega lihtsalt füüsiliselt peksa saada, rääkimata kiriku vande alla panemisest, kollektiivsest palvusest teie „päästmiseks“ või inimese energiast toitujate kõrgemate süsteemiisandate kättemaksudest.\\r\\n', '\\r\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASSCBtkZR6e-",
        "colab_type": "text"
      },
      "source": [
        "Note that each line in the file ends with a newline character (except for the last, possibly). So each element in `lines` array also ends in a new line. Often it's beneficial to get rid of the line-ending new-lines. This can be accomplished like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq173fR_R6fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = codecs.open('parasiitlusest.txt', 'r', 'utf-8')\n",
        "lines = [l.strip() for l in f.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONnPGsB1R6fE",
        "colab_type": "code",
        "outputId": "35c0d07c-ec3a-408c-c2fd-a770302f3646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(lines[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parasiitlus on teiste energiast toitumine ilma, et midagi samaväärset vastu antaks ehk saamahimu üks väljendusvorme. Parasiitluse vastand on taimeriigis levinud sümbioos (botaanikas tuntud mõiste), kus toimub vastastikku kasulik kaubavahetus.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A0CRpaUR6fK",
        "colab_type": "text"
      },
      "source": [
        "Note that we had to reopen the file in order to call `readlines()` on `f` again.\n",
        "\n",
        "## List comprehension\n",
        "\n",
        "The line-end stripping was implemented using a Python construct called list comprehension. It's incredibly useful when working with all kind of data. It makes it easy to apply a certain function to all elements of a list and filter list elements. Some examples in the following."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImIFQU0LR6fL",
        "colab_type": "code",
        "outputId": "d7f1df08-03dd-4d95-ba40-bb42a839ccc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "[l.upper() for l in lines][0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PARASIITLUS ON TEISTE ENERGIAST TOITUMINE ILMA, ET MIDAGI SAMAVÄÄRSET VASTU ANTAKS EHK SAAMAHIMU ÜKS VÄLJENDUSVORME. PARASIITLUSE VASTAND ON TAIMERIIGIS LEVINUD SÜMBIOOS (BOTAANIKAS TUNTUD MÕISTE), KUS TOIMUB VASTASTIKKU KASULIK KAUBAVAHETUS.',\n",
              " 'PARASIITLUS ON HINGESTATUD ISIKUTELE PARATAMATU EHK ÜLIVAJALIK ÕPPETUND, MIS HAKKAB PIHTA JUBA AINURAKSETEL LOOMADEL VIIRUSTE JA BAKTERITE NÄOL JA MAISE INIMHINGE TASANDIL LÕPEB PARALLEELMAAILMADE VALGETE DRAAKONITE (KÕRGTASANDI REPTILOIDIDE = KEHA + MÕISTUS, HING PUUDUB) PAKUTAVATE MANIPULATSIOONIDE TUNDMAÕPPIMISEGA.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyCXsfhSR6fR",
        "colab_type": "code",
        "outputId": "ceecccb1-9e28-4852-9f7b-8ea706214999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[len(l) for l in lines][0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[242, 319, 398, 1106, 560]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQvn-YpvR6fX",
        "colab_type": "text"
      },
      "source": [
        "It's also easy to filter lists:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA5ZOMD0R6fZ",
        "colab_type": "code",
        "outputId": "9b0efaae-4b9a-4e4f-f25f-00dc9d78e9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "[l for l in lines if len(l) > 1000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Parasiitluse üks erivorme on vampiirlus, kus energia imemine toimub füüsilist kontakti omamata, kasutades selleks peenmateriaalseid struktuure. Ainuke abi vampiirile on mitte lasta tal teie üle võimutseda – et ta õpiks ise energiat tootma. Vampiir on läinud elus lihtsama vastupanu teed. Selle asemel, et ise energiat toota või tootmisprotsessis osaleda, on ta teinud otsuse talle vajalikku energia varastada. Lihtsama vastupanu teed minemine on alati raskem tee. Sellel lihtsal põhjusel, et endale võetud õppetunnid tuleb omandada niikuinii pluss katsumused, mis saadakse sellel nn. lihtsal teel. Sellest momendist, kui inimene on teinud otsuse lihtsama vastupanu teed minna, hakkab ta hingel raske – ta on läinud oma südame-tunnistusega vastuollu. Südametunnistusega vastuollu minek on hinge eitamine. Seda mida pole, seda on lihtne ära anda. Seda teadmist kasutab ära orjandussüsteem, meelitades inimesi oma hingest loobuma. See, kes oma hingeosa ära on andnud, loobub paratamatult ka oma tegutsemise jõust. See, kes on jõuetu, ei suuda enam oma probleeme lahendada ehk ta on oma probleemide ees jõuetu.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NqcyY6TR6fe",
        "colab_type": "code",
        "outputId": "ff105d43-3597-4a56-fc0b-58a6c4b60b83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "[l for l in lines if l.startswith('V')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vampiir ei saa õnnelik olla, kuna ta on ennast ise loomingust välja lülitanud. Looming tähendab isetegemist ja selle kaudu oma isiksuse arendamist. Kui teistelt energiat valmiskujul võetakse, siis enda sees olevad energia tootmissüsteemid jäävad tööta ja manduvad. Mida kauem inimvampiir tegutseb, seda suuremasse sõltuvusse ta teiste inimeste energiast jääb. Lõpuks on tema eesmärgiks ja pidevaks tegutsemisliiniks probleem, kuidas teistelt energiat kätte saada. Teda ei huvita see, mis ohvrist saab – peaasi et oma eluks vajaliku portsu energiat kätte saaks.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnQ0b1-8R6fk",
        "colab_type": "text"
      },
      "source": [
        "## Regular expressions\n",
        "Now, let's check how regular expressions can be used in Python.\n",
        "\n",
        "The most important functions for working with regular expressions are `match`, `sub`, `findall` ja `split`, all from the `re` Python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4OEeLs4R6fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPZMwOXrR6fq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numbers = re.findall(\"\\d+\", \"I have 22 dogs and 6 cats\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I60X2jupR6fv",
        "colab_type": "code",
        "outputId": "e69ff3a9-eeec-4979-f435-8339bc28fbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(numbers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['22', '6']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51pjaf8kR6f1",
        "colab_type": "text"
      },
      "source": [
        "The `findall` function can be used as a very simple tokenizer. E.g., let's find all matches that consists exclusivey of \"word\" characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk9Ew8YGR6f4",
        "colab_type": "code",
        "outputId": "4864357e-cc69-4e5f-c182-30095ee0ea6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "words = re.findall(\"\\w+\", \"I have 22 dogs and 6 cats. I love animals.\")\n",
        "print(words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'have', '22', 'dogs', 'and', '6', 'cats', 'I', 'love', 'animals']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzdOEBvIR6gB",
        "colab_type": "text"
      },
      "source": [
        "Since Python 3, the `\\w` character class also works for non-ASCII characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH-dfROKR6gC",
        "colab_type": "code",
        "outputId": "929f980f-568e-46b9-fff0-bbca557cf9a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "re.findall(\"\\w+\", \"Ülol on kaks õuna ja kolm garaaži\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ülol', 'on', 'kaks', 'õuna', 'ja', 'kolm', 'garaaži']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Qud3T6R6gH",
        "colab_type": "text"
      },
      "source": [
        "An alternative way to perform tokenization is to use the `re.split()` method. In this case, we have to specify a regular expression that defines places where words are split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7-mc_KjR6gJ",
        "colab_type": "code",
        "outputId": "2a52a933-7df0-4f60-88cb-4e0d838a8cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        " re.split(\"[\\s,.!?]+\", \"I have 22 dogs and 6 cats. I love animals.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'have', '22', 'dogs', 'and', '6', 'cats', 'I', 'love', 'animals', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjn2hnpVR6gQ",
        "colab_type": "text"
      },
      "source": [
        "Note that this results in an empty element at the end of the token list. This is because `re.split()` splits on the last \".\", and puts the resulting empty string on the right also to the result. But it's easy to fix this using list comprehension:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z154Zi30R6gR",
        "colab_type": "code",
        "outputId": "62654582-514f-4d2f-8d2a-6917b0f9640a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "[token for token in re.split(\"[\\s,.!?]+\", \"I have 22 dogs and 6 cats. I love animals.\") if len(token) > 0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'have', '22', 'dogs', 'and', '6', 'cats', 'I', 'love', 'animals']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUdRZcKnR6gV",
        "colab_type": "text"
      },
      "source": [
        "Another useful regexp method is `match()`. It checks whether the given start of the given string matches a regexp. If yes, a Match object is returned that contans information about the match. If there is no match, `None` is returned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X526eeQ2R6gX",
        "colab_type": "code",
        "outputId": "a885186c-f79a-41c9-d9ab-fdea9237f309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "m = re.match(\"Tallinn?\", \"Tallinnas sadas lund.\")\n",
        "if m:\n",
        "    print(m.group(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tallinn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2PShVhZR6gb",
        "colab_type": "text"
      },
      "source": [
        "Retrieving the match groups is one of the most useful functionalities of the `match()` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56tHz1T0R6gc",
        "colab_type": "code",
        "outputId": "3c5fb9ff-fca6-4c1f-b149-a11346a2da1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "m = re.match(\"(.+), (\\d{5}) (Tallinn|Tartu)\", \"Akadeemia tee 21, 10126 Tallinn\")\n",
        "if m:\n",
        "    print(m.group(1))\n",
        "    print(m.group(2))\n",
        "    print(m.group(3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Akadeemia tee 21\n",
            "10126\n",
            "Tallinn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd80nAk7R6gh",
        "colab_type": "text"
      },
      "source": [
        "The `match()` function checks whether the start of the string matches the rexexp. If you want to check whether the full string matches the regexp, just add the \"line end anchor\" to the end of the regexp:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5Moal1VR6gj",
        "colab_type": "code",
        "outputId": "9ca7bed6-5fc8-4add-b5e6-81f831739dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if re.match(\"\\d+\", \"12345 foo\"): \n",
        "    print(\"Match!\") \n",
        "else: \n",
        "    print(\"No match\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Match!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6JCYFqMR6gn",
        "colab_type": "code",
        "outputId": "9fc340fc-311d-4bb4-cc88-0248a3e2ac97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if re.match(\"\\d+$\", \"12345 foo\"): \n",
        "    print(\"Match!\") \n",
        "else: \n",
        "    print(\"No match\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bJIYBnKR6gq",
        "colab_type": "text"
      },
      "source": [
        "For regexp-based substitution, the `re.sub()` function can be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m5TiTI9R6gr",
        "colab_type": "code",
        "outputId": "ceca7cdd-beb7-4ac0-e334-c86aaec610e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "email_address = \"Please contact us at: xyz@foo.com\"\n",
        "new_email_address = re.sub(r'([\\w\\.-]+)@([\\w\\.-]+)', r'support@foo.com', email_address)\n",
        "print(new_email_address)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please contact us at: support@foo.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcoKmhBbR6gv",
        "colab_type": "text"
      },
      "source": [
        "The `sub()` method allows using back-references. But in this case it's useful to specify the replacement string using the r'string' method (raw string), otherwise the `\\1` element will be interpreted as \"character with ASCII code 1\" by Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUgqPcB6R6gw",
        "colab_type": "code",
        "outputId": "2f47821c-9fcd-40d5-9259-dec7d4d2b8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "email_address = \"Please contact us at: info@nordea.ee\"\n",
        "new_email_address = re.sub('([\\w\\.-]+)@nordea.ee', r'\\1@luminor.ee', email_address)\n",
        "print(new_email_address)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please contact us at: info@luminor.ee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzn2qcWAR6iU",
        "colab_type": "text"
      },
      "source": [
        "## spaCy\n",
        "\n",
        "SpaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. It's a bit similar to EstNLTK, but has a different API, and covers more languages. It is highly recommended when working with English texts. See https://spacy.io/usage/spacy-101"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGfHB-_jR6iV",
        "colab_type": "text"
      },
      "source": [
        "For installation instructions of spaCy, see https://spacy.io/usage/.\n",
        "\n",
        "SpaCY is already installed under python3 in the lab class computers. However, the language-specific models are not installed. To install them, use the following command in the terminal:\n",
        "\n",
        "`pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz --user`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8oJ-U7hR6iW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "# Use the follwoing if the model file was installed globally\n",
        "nlp = spacy.load('en')\n",
        "# if the model file was used locally, as in explained above, i.e., if you are in a lab computer\n",
        "# nlp = spacy.load('en-core-web-sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNlS48BrR6iY",
        "colab_type": "code",
        "outputId": "5432bc74-ba1c-48c4-8da9-6b1bd3e1fb7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "          token.shape_, token.is_alpha, token.is_stop)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple apple PROPN NNP nsubj Xxxxx True False\n",
            "is be VERB VBZ aux xx True True\n",
            "looking look VERB VBG ROOT xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "buying buy VERB VBG pcomp xxxx True False\n",
            "U.K. u.k. PROPN NNP compound X.X. False False\n",
            "startup startup NOUN NN dobj xxxx True False\n",
            "for for ADP IN prep xxx True True\n",
            "$ $ SYM $ quantmod $ False False\n",
            "1 1 NUM CD compound d False False\n",
            "billion billion NUM CD pobj xxxx True False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv853v5lR6ib",
        "colab_type": "text"
      },
      "source": [
        "### Named entity recognition\n",
        "\n",
        "SpaCy can also do named entity recognition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0LHytIrR6ic",
        "colab_type": "code",
        "outputId": "514988c7-015e-4dfa-fc7f-fdb341b54604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cww-QQgFR6if",
        "colab_type": "text"
      },
      "source": [
        "Named entites can be nicely visualized using spaCy's displaCy library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QyHT9TSR6ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ym_lTDdR6ij",
        "colab_type": "code",
        "outputId": "a3a0749d-46d1-4f26-8c06-98d1273e06a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is looking at buying \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    U.K.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " startup for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    $1 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEGCMstpR6in",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRkSDgUrTshN",
        "colab_type": "text"
      },
      "source": [
        "## StanfordNLP\n",
        "\n",
        "Quite recently, Stanford released a new open source NLP library called StanfordNLP. The nice thing about this is that it supports much m ore languages than spaCy -- 53 in total. Estonian is among the supported languages.\n",
        "\n",
        "Is your native language supported? See https://stanfordnlp.github.io/stanfordnlp/installation_download.html#human-languages-supported-by-stanfordnlp.\n",
        "\n",
        "Let's install StanfordNLP and explore what it can do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKZxruR9TvF8",
        "colab_type": "code",
        "outputId": "68bca176-1b4e-451a-c6af-29191ee0092d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "! pip install stanfordnlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stanfordnlp in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (2.18.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (4.28.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (3.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.14.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (3.0.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (40.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hldkqYyfUoDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stanfordnlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRfzYvCvUtQ8",
        "colab_type": "text"
      },
      "source": [
        "We'll experiment with Estonian models. Feel free to choose any other supported language. The language codes can be seen here: https://stanfordnlp.github.io/stanfordnlp/installation_download.html#human-languages-supported-by-stanfordnlp\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOeLKEwsU4SD",
        "colab_type": "code",
        "outputId": "c5c5e17e-2f3f-4517-abea-988a4f7972fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "stanfordnlp.download('et')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"et_edt\" for language \"et\".\n",
            "Would you like to download the models for: et_edt now? (Y/n)\n",
            "y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: et_edt\n",
            "Download location: /root/stanfordnlp_resources/et_edt_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 540M/540M [00:17<00:00, 31.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/et_edt_models.zip\n",
            "Extracting models file for: et_edt\n",
            "Cleaning up...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ6XqrnLU6g5",
        "colab_type": "code",
        "outputId": "d363f162-3128-4e8d-b5fb-bcddba0ed82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(lang=\"et\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: cpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/et_edt_models/et_edt_tokenizer.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/et_edt_models/et_edt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/et_edt_models/et_edt.pretrain.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/et_edt_models/et_edt_lemmatizer.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "---\n",
            "Loading: depparse\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/et_edt_models/et_edt_parser.pt', 'pretrain_path': '/root/stanfordnlp_resources/et_edt_models/et_edt.pretrain.pt', 'lang': 'et', 'shorthand': 'et_edt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tF0f4xFVXwX",
        "colab_type": "text"
      },
      "source": [
        "We'll use the first line of the text file we loaded above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi7716ODVVuB",
        "colab_type": "code",
        "outputId": "50d78e33-611c-408a-de05-78dfc39199f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "text = lines[0]\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parasiitlus on teiste energiast toitumine ilma, et midagi samaväärset vastu antaks ehk saamahimu üks väljendusvorme. Parasiitluse vastand on taimeriigis levinud sümbioos (botaanikas tuntud mõiste), kus toimub vastastikku kasulik kaubavahetus.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xth9IpnVFzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPBsfBvMVlF4",
        "colab_type": "text"
      },
      "source": [
        "The `doc` object is now a list of sentences, which in turn are lists of words. Let's look at the first sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTQlAlSxVOhS",
        "colab_type": "code",
        "outputId": "0acfc973-986b-49d6-e93e-c7d85df39d4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "doc.sentences[0].print_tokens()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Token index=1;words=[<Word index=1;text=Parasiitlus;lemma=parasiitlus;upos=NOUN;xpos=S;feats=Case=Nom|Number=Sing;governor=5;dependency_relation=nsubj:cop>]>\n",
            "<Token index=2;words=[<Word index=2;text=on;lemma=olema;upos=AUX;xpos=V;feats=Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin|Voice=Act;governor=5;dependency_relation=cop>]>\n",
            "<Token index=3;words=[<Word index=3;text=teiste;lemma=teine;upos=DET;xpos=P;feats=Case=Gen|Number=Plur|PronType=Dem;governor=4;dependency_relation=det>]>\n",
            "<Token index=4;words=[<Word index=4;text=energiast;lemma=energia;upos=NOUN;xpos=S;feats=Case=Ela|Number=Sing;governor=5;dependency_relation=nmod>]>\n",
            "<Token index=5;words=[<Word index=5;text=toitumine;lemma=toitumine;upos=NOUN;xpos=S;feats=Case=Nom|Number=Sing;governor=0;dependency_relation=root>]>\n",
            "<Token index=6;words=[<Word index=6;text=ilma;lemma=ilma;upos=ADV;xpos=D;feats=_;governor=5;dependency_relation=advmod>]>\n",
            "<Token index=7;words=[<Word index=7;text=,;lemma=,;upos=PUNCT;xpos=Z;feats=_;governor=12;dependency_relation=punct>]>\n",
            "<Token index=8;words=[<Word index=8;text=et;lemma=et;upos=SCONJ;xpos=J;feats=_;governor=12;dependency_relation=mark>]>\n",
            "<Token index=9;words=[<Word index=9;text=midagi;lemma=miski;upos=PRON;xpos=P;feats=Case=Par|Number=Sing|PronType=Ind;governor=12;dependency_relation=obj>]>\n",
            "<Token index=10;words=[<Word index=10;text=samaväärset;lemma=sama_väärne;upos=ADJ;xpos=A;feats=Case=Par|Degree=Pos|Number=Sing;governor=9;dependency_relation=amod>]>\n",
            "<Token index=11;words=[<Word index=11;text=vastu;lemma=vastu;upos=ADV;xpos=D;feats=_;governor=12;dependency_relation=compound:prt>]>\n",
            "<Token index=12;words=[<Word index=12;text=antaks;lemma=andma;upos=VERB;xpos=V;feats=Mood=Cnd|Tense=Pres|VerbForm=Fin|Voice=Act;governor=5;dependency_relation=acl>]>\n",
            "<Token index=13;words=[<Word index=13;text=ehk;lemma=ehk;upos=CCONJ;xpos=J;feats=_;governor=16;dependency_relation=cc>]>\n",
            "<Token index=14;words=[<Word index=14;text=saamahimu;lemma=saamahim;upos=NOUN;xpos=S;feats=Case=Gen|Number=Sing;governor=16;dependency_relation=nmod>]>\n",
            "<Token index=15;words=[<Word index=15;text=üks;lemma=üks;upos=DET;xpos=P;feats=Case=Nom|Number=Sing|PronType=Ind;governor=16;dependency_relation=det>]>\n",
            "<Token index=16;words=[<Word index=16;text=väljendusvorme;lemma=väljendus_vorm;upos=NOUN;xpos=S;feats=Case=Nom|Number=Sing;governor=12;dependency_relation=conj>]>\n",
            "<Token index=17;words=[<Word index=17;text=.;lemma=.;upos=PUNCT;xpos=Z;feats=_;governor=5;dependency_relation=punct>]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsCddq47WsAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRLD_ousWsrt",
        "colab_type": "text"
      },
      "source": [
        "It's easy to extract the word and it's lemma, and a POS (part-of-speech, i.e., word type) tag:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y03VLtJtVyn_",
        "colab_type": "code",
        "outputId": "0f1c2e92-a6d9-4c8d-de62-37301d42796e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "source": [
        "for i, sentence in enumerate(doc.sentences):\n",
        "  print(\"-----------------\")\n",
        "  print(\"Sentence %d\" % i)\n",
        "  for word in sentence.words:\n",
        "    print(\"%16s %16s %5s\" % (word.text, word.lemma, word.upos))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------\n",
            "Sentence 0\n",
            "     Parasiitlus      parasiitlus  NOUN\n",
            "              on            olema   AUX\n",
            "          teiste            teine   DET\n",
            "       energiast          energia  NOUN\n",
            "       toitumine        toitumine  NOUN\n",
            "            ilma             ilma   ADV\n",
            "               ,                , PUNCT\n",
            "              et               et SCONJ\n",
            "          midagi            miski  PRON\n",
            "     samaväärset      sama_väärne   ADJ\n",
            "           vastu            vastu   ADV\n",
            "          antaks            andma  VERB\n",
            "             ehk              ehk CCONJ\n",
            "       saamahimu         saamahim  NOUN\n",
            "             üks              üks   DET\n",
            "  väljendusvorme   väljendus_vorm  NOUN\n",
            "               .                . PUNCT\n",
            "-----------------\n",
            "Sentence 1\n",
            "    Parasiitluse      parasiitlus  NOUN\n",
            "         vastand          vastand  NOUN\n",
            "              on            olema   AUX\n",
            "     taimeriigis       taime_riik  NOUN\n",
            "         levinud         levi=nud   ADJ\n",
            "        sümbioos         sümbioos  NOUN\n",
            "               (                ( PUNCT\n",
            "      botaanikas        botaanika  NOUN\n",
            "          tuntud           tuntud   ADJ\n",
            "          mõiste           mõiste  NOUN\n",
            "               )                ) PUNCT\n",
            "               ,                , PUNCT\n",
            "             kus              kus   ADV\n",
            "          toimub          toimuma  VERB\n",
            "     vastastikku      vastastikku   ADV\n",
            "         kasulik          kasulik   ADJ\n",
            "    kaubavahetus    kauba_vahetus  NOUN\n",
            "               .                . PUNCT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_sT3SRyXQ30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}